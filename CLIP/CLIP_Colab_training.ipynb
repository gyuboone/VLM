{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P782xKbe4m7j",
        "outputId": "144ea180-6902-4185-e095-04bcc9aa7ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'VLM'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 79 (delta 17), reused 70 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (79/79), 1.73 MiB | 43.19 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/gyuboone/VLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd /content/VLM/CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/VLM/CLIP\n"
          ]
        }
      ],
      "source": [
        "! pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nCSrbhHdi0_",
        "outputId": "3f145d19-0bd5-409a-b064-952391fe81ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CikVlCDDOohd",
        "outputId": "78a2fc9b-a699-41fc-8a3c-cc2a46c564f2"
      },
      "outputs": [],
      "source": [
        "! mkdir data\n",
        "! mkdir data/mscoco\n",
        "! wget http://images.cocodataset.org/zips/train2017.zip -O data/mscoco/train2017.zip\n",
        "! unzip data/mscoco/train2017.zip -d data/mscoco\n",
        "\n",
        "! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O data/mscoco/annotations_trainval2017.zip\n",
        "! unzip data/mscoco/annotations_trainval2017.zip -d data/mscoco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYqtPKcUvv8u",
        "outputId": "3e615371-5579-4312-c5ff-cc1217f50d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118287\n"
          ]
        }
      ],
      "source": [
        "!ls ./data/mscoco/train2017 -l | grep ^- | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Colab 무료로 118287개의 data를 training 하는 것이 불가능하여 data의 일부만 남김"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8eV7KSgAwIvw"
      },
      "outputs": [],
      "source": [
        "!find ./data/mscoco/train2017 -name \"0000001*\" -type f -delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mprh0bzyxL8j",
        "outputId": "d6fad8bf-7985-46fe-da87-a4e0f49c3926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98063\n"
          ]
        }
      ],
      "source": [
        "!ls ./data/mscoco/train2017 -l | grep ^- | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LoraKlkIxO9Z"
      },
      "outputs": [],
      "source": [
        "!find ./data/mscoco/train2017 -name \"0000002*\" -type f -delete\n",
        "!find ./data/mscoco/train2017 -name \"0000003*\" -type f -delete\n",
        "!find ./data/mscoco/train2017 -name \"0000004*\" -type f -delete\n",
        "!find ./data/mscoco/train2017 -name \"0000005*\" -type f -delete\n",
        "!find ./data/mscoco/train2017 -name \"0000006*\" -type f -delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P_HlbVFxTMG",
        "outputId": "04d549ef-e82f-4253-96f4-ec3a536fdfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20368\n"
          ]
        }
      ],
      "source": [
        "!ls ./data/mscoco/train2017 -l | grep ^- | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0kJzoA6y0pm",
        "outputId": "1cafb337-911e-49a0-f832-bcb4658069cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "0th epoch starting.\n",
            "[Epoch 0th] loss: 4.2644\n",
            "1th epoch starting.\n",
            "[Epoch 1th] loss: 4.2445\n",
            "2th epoch starting.\n",
            "[Epoch 2th] loss: 4.2242\n",
            "3th epoch starting.\n",
            "[Epoch 3th] loss: 4.2158\n",
            "4th epoch starting.\n",
            "[Epoch 4th] loss: 4.2056\n",
            "5th epoch starting.\n",
            "[Epoch 5th] loss: 4.2006\n",
            "Time ellapsed in training is: 1827.7767841815948\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from dataloader.dataset import CLIP_COCO_dataset\n",
        "from dataloader.data_loaders import get_dataloader\n",
        "\n",
        "from CLIP import CLIP\n",
        "from utils.simple_tokenizer import SimpleTokenizer\n",
        "from utils import set_seed, mkdir\n",
        "\n",
        "import time\n",
        "\n",
        "from torch.optim import Adam, AdamW # both are same but AdamW has a default weight decay\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "################## setting start ##################\n",
        "lr = 0.0001\n",
        "batch_size = 96\n",
        "epochs = 6\n",
        "\n",
        "\n",
        "# fixing seed\n",
        "seed = 7\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# text tokenizer (text encoder에 사용)\n",
        "tokenizer = SimpleTokenizer()\n",
        "\n",
        "\n",
        "# setting model\n",
        "model_params = {'embed_dim' : 1024,\n",
        "  'image_resolution' : 224,\n",
        "  'vision_layers' : [3, 4, 6, 3],\n",
        "  'vision_width': 64,\n",
        "  'vision_patch_size' : 0 ,# ideally it should be none\n",
        "  'context_length' : 77,\n",
        "  'vocab_size' : 49408,\n",
        "  'transformer_width' : 512,\n",
        "  'transformer_heads' : 8,\n",
        "  'transformer_layers' : 6,# 12 in CLIP\n",
        "}\n",
        "model_params['vision_layers'] = tuple(model_params['vision_layers'])\n",
        "model_params['vision_patch_size'] = None\n",
        "model = CLIP(**model_params).to(device)\n",
        "\n",
        "# pth load 후 학습 가능. \n",
        "# model.load_state_dict(torch.load('model_weights.pth', map_location=device))\n",
        "\n",
        "# setting dataset\n",
        "train_img_dir = 'data/mscoco/train2017'\n",
        "train_annotation_file = 'data/mscoco/annotations/captions_train2017.json'\n",
        "\n",
        "train_dataset = CLIP_COCO_dataset(train_annotation_file, train_img_dir, tokenizer)\n",
        "train_dataloader = get_dataloader(train_dataset, batch_size, is_train=True)\n",
        "\n",
        "# setting optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# setting loss function\n",
        "def loss_function(logits_img, logits_txt):\n",
        "\n",
        "    labels = torch.arange(logits_img.shape[0]).to(device)\n",
        "\n",
        "    loss_i = F.cross_entropy(logits_img, labels)\n",
        "    loss_t = F.cross_entropy(logits_txt, labels)\n",
        "    return (loss_i + loss_t) / 2\n",
        "\n",
        "################## setting end ##################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################ training epoch start #################\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"{epoch}th epoch starting.\")\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        img, txt = batch\n",
        "\n",
        "        img = img.to(device)\n",
        "        txt = txt.to(device)\n",
        "\n",
        "        logits_img, logits_txt = model(img, txt)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(logits_img,logits_txt)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"[Epoch {epoch}th] loss: {running_loss/len(train_dataloader):.4f}\")\n",
        "end = time.time()\n",
        "################ training epoch end #################\n",
        "print(f\"Time ellapsed in training is: {end-start}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9HrXWH99JdxX"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model_weights_2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K4Md8dKcK8K4"
      },
      "outputs": [],
      "source": [
        "# pth 저장\n",
        "\n",
        "! cp model_weights_2.pth ./drive/MyDrive/CLIP_MSCOCO.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
