# CLIP 구현 및 training

pytorch로 CLIP 구현 및 [MS-COCO 2017](https://cocodataset.org/#download) captions 활용하여 CLIP training

## 출처

#### 1. CLIP
[CLIP official repository](https://github.com/openai/CLIP)\
[CLIP official blog](https://openai.com/index/clip/)\
[CLIP paper](https://arxiv.org/pdf/2103.00020)
  
#### 2. CLIP training 
official repository에는 train.py가 없음\
[CLIP training repository](https://github.com/revantteotia/clip-training)

#### 3. transformer 이해 및 구현 (multi-headed attention)
[Attention Is All You Need](https://arxiv.org/pdf/1706.03762)\
[3Blue 1Brown Youtube(for concept)](https://www.youtube.com/watch?v=eMlx5fFNoYc)\
[Andrej Karpathy Youtube : Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)\
[Harvards NLP transformer implementation (*Highly recommended)](http://nlp.seas.harvard.edu/2018/04/03/attention.html#attention)\
[Jay Alammar : The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)